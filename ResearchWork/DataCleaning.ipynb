{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to clean car details seperate it\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "def new_car_details_cleaning(file_path,output_path):\n",
    "  df = pd.read_excel(file_path)\n",
    "\n",
    "# Specify the columns containing dictionary string\n",
    "  dict_columns = ['new_car_detail', 'new_car_overview', 'new_car_feature', 'new_car_specs']\n",
    "  \n",
    "# Create an Excel writer to save each dictionary as a separate sheet\n",
    "  #output_path = r'C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\delhi.xlsx'\n",
    "  with pd.ExcelWriter(output_path) as writer:\n",
    "    for col in dict_columns:\n",
    "        # Check if the column exists in the DataFrame\n",
    "        if col in df.columns:\n",
    "            # Convert each cell in the column from a dictionary string to an actual dictionary\n",
    "            try:\n",
    "                column_data = df[col].dropna().apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else {})\n",
    "            except ValueError as e:\n",
    "                print(f\"Error parsing column {col}: {e}\")\n",
    "                continue  # Skip this column if there's an error\n",
    "\n",
    "            # Normalize each dictionary into a DataFrame and combine into a single DataFrame for the sheet\n",
    "            table_df = pd.json_normalize(column_data.tolist())\n",
    "\n",
    "            # Debug: print the head of the table to confirm data processing\n",
    "            print(f\"Processed data for column {col}:\\n\", table_df.head())\n",
    "\n",
    "            # Write each table to a separate sheet\n",
    "            table_df.to_excel(writer, sheet_name=col, index=False)\n",
    "        else:\n",
    "            print(f\"Column '{col}' does not exist in the DataFrame.\")\n",
    "\n",
    "# Output path to download the file\n",
    "  print(\"Data written to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to clean car_overveiw file\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def clean_and_expand_new_car_overview(file_path, sheet_name='new_car_overview', data_column='top'):\n",
    "    \"\"\"\n",
    "    This function reads an Excel file, cleans the data, expands dictionary-like data into separate columns,\n",
    "    and saves the cleaned data back to the same Excel file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the Excel file.\n",
    "    - sheet_name (str): The name of the sheet to process. Default is 'new_car_overview'.\n",
    "    - data_column (str): The column containing dictionary-like data. Default is 'top'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Function to remove outer brackets from the data\n",
    "    def remove_outer_brackets(value):\n",
    "        if isinstance(value, str) and value.startswith('[') and value.endswith(']'):\n",
    "            return value[1:-1]  # Remove first and last character (outer brackets)\n",
    "        return value\n",
    "\n",
    "    # Apply the function to remove outer brackets from the specified column\n",
    "    df[data_column] = df[data_column].apply(remove_outer_brackets)\n",
    "\n",
    "    # Function to parse each cell's dictionary-like data and convert it into a dictionary of columns\n",
    "    def expand_data(cell_value):\n",
    "        try:\n",
    "            # Convert the string representation of dictionary list to actual Python list\n",
    "            data_list = ast.literal_eval(cell_value)\n",
    "            # Create a dictionary to hold the expanded data for each row\n",
    "            expanded_row = {}\n",
    "            # Extract 'key', 'value', and 'icon' for each item and set them in the expanded row\n",
    "            for item in data_list:\n",
    "                key = item.get('key')\n",
    "                value = item.get('value')\n",
    "                icon = item.get('icon')\n",
    "                # Create columns for 'value' and 'icon' associated with each key\n",
    "                expanded_row[f'{key}'] = value\n",
    "                expanded_row[f'{key} Icon'] = icon\n",
    "            return expanded_row\n",
    "        except (ValueError, SyntaxError):\n",
    "            return {}\n",
    "\n",
    "    # Apply the function and expand each cell into separate columns\n",
    "    expanded_data = df[data_column].apply(expand_data).apply(pd.Series)\n",
    "\n",
    "    # Concatenate the expanded columns with the original DataFrame (excluding the original data column)\n",
    "    df_cleaned = pd.concat([df.drop(columns=[data_column]), expanded_data], axis=1)\n",
    "\n",
    "    # Write the cleaned DataFrame back to the same file, replacing the original sheet\n",
    "    with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "        df_cleaned.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(\"The data has been expanded into columns and saved to the same file, with 'key' as column names and 'value' and 'icon' as data.\")\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to clean car_feature file\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def clean_and_expand_new_car_feature(file_path, sheet_name='new_car_feature'):\n",
    "    \"\"\"\n",
    "    This function reads an Excel file, cleans the data, expands list of dictionaries into separate columns,\n",
    "    and saves the cleaned data back to the same Excel file.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The path to the Excel file.\n",
    "    - sheet_name (str): The name of the sheet to process. Default is 'new_car_feature'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    # Function to remove outer brackets from the data\n",
    "    def remove_outer_brackets(value):\n",
    "        if isinstance(value, str) and value.startswith('[') and value.endswith(']'):\n",
    "            return value[1:-1]  # Remove first and last character (outer brackets)\n",
    "        return value\n",
    "\n",
    "    # Apply the function to remove outer brackets from the 'top' and 'data' columns\n",
    "    df['top'] = df['top'].apply(remove_outer_brackets)\n",
    "    df['data'] = df['data'].apply(remove_outer_brackets)\n",
    "\n",
    "    # Function to expand each list of dictionaries within a cell\n",
    "    def expand_dict_list(cell_value):\n",
    "        try:\n",
    "            # Convert cell value to list of dictionaries\n",
    "            data_list = ast.literal_eval(cell_value)\n",
    "            # Extract each dictionary's 'value' into a new list for each row\n",
    "            values = [item['value'] for item in data_list if 'value' in item]\n",
    "            return values\n",
    "        except (ValueError, SyntaxError):\n",
    "            return []\n",
    "\n",
    "    # Expand the 'top' and 'data' columns separately\n",
    "    top_expanded = df['top'].apply(expand_dict_list).apply(pd.Series)\n",
    "    data_expanded = df['data'].apply(expand_dict_list).apply(pd.Series)\n",
    "\n",
    "    # Rename columns to avoid duplication in the final table\n",
    "    top_expanded.columns = [f\"top_{i+1}\" for i in range(top_expanded.shape[1])]\n",
    "    data_expanded.columns = [f\"data_{i+1}\" for i in range(data_expanded.shape[1])]\n",
    "\n",
    "    # Concatenate expanded data with original DataFrame (excluding 'top' and 'data' columns)\n",
    "    df_cleaned = pd.concat([df.drop(columns=['top', 'data']), top_expanded, data_expanded], axis=1)\n",
    "\n",
    "    # Save the updated data back to the same sheet in the original Excel file\n",
    "    with pd.ExcelWriter(file_path, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "        df_cleaned.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(\"The data has been expanded and saved to the same sheet in the original file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to clean car_specs sheet\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def clean_new_car_specs(file_path):\n",
    "    \"\"\"\n",
    "    Cleans the 'new_car_specs' sheet in the given Excel file.\n",
    "    - Converts JSON-like strings into structured data.\n",
    "    - Flattens key-value pairs into separate columns.\n",
    "    - Saves the cleaned data back to the same file.\n",
    "\n",
    "    :param file_path: Path to the Excel file.\n",
    "    \"\"\"\n",
    "    # Load the Excel file\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    \n",
    "    # Load the 'new_car_specs' sheet\n",
    "    df_specs = pd.read_excel(xls, sheet_name='new_car_specs')\n",
    "\n",
    "    # Function to safely convert stringified lists/dicts to Python objects\n",
    "    def safe_eval(val):\n",
    "        try:\n",
    "            return ast.literal_eval(val) if isinstance(val, str) else val\n",
    "        except (SyntaxError, ValueError):\n",
    "            return None\n",
    "\n",
    "    # Apply transformation to 'top' and 'data' columns\n",
    "    if 'top' in df_specs.columns:\n",
    "        df_specs['top'] = df_specs['top'].apply(safe_eval)\n",
    "    \n",
    "    if 'data' in df_specs.columns:\n",
    "        df_specs['data'] = df_specs['data'].apply(safe_eval)\n",
    "\n",
    "    # Flatten 'top' column into separate columns if it contains data\n",
    "    if df_specs['top'].notna().any():\n",
    "        top_df = df_specs['top'].apply(lambda x: {d['key']: d['value'] for d in x} if isinstance(x, list) else {}).apply(pd.Series)\n",
    "        df_specs = pd.concat([df_specs, top_df], axis=1)\n",
    "\n",
    "    # Drop unneeded columns\n",
    "    df_specs.drop(columns=['heading', 'commonIcon', 'top'], inplace=True, errors='ignore')\n",
    "\n",
    "    # Save cleaned data back to the same file\n",
    "    with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        df_specs.to_excel(writer, sheet_name='new_car_specs', index=False)\n",
    "\n",
    "    print(\"Data cleaning complete. File updated successfully.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Delhi cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\delhi.xlsx'\n",
    "\n",
    "clean_and_expand_new_car_overview(file_path)\n",
    "\n",
    "new_car_details_cleaning(r'c:\\Users\\loges\\Downloads\\delhi_cars (3).xlsx',r'C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\delhi.xlsx')\n",
    "\n",
    "clean_and_expand_new_car_feature(file_path)\n",
    "\n",
    "clean_new_car_specs(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning kolkata cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\kolkata_cars.xlsx\"\n",
    "\n",
    "new_car_details_cleaning(file_path,output_path=file_path)\n",
    "\n",
    "clean_and_expand_new_car_overview(file_path)\n",
    "\n",
    "clean_and_expand_new_car_feature(file_path)\n",
    "\n",
    "clean_new_car_specs(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Jaipur cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\jaipur_cars.xlsx\"\n",
    "\n",
    "new_car_details_cleaning(file_path,output_path=file_path)\n",
    "\n",
    "clean_and_expand_new_car_overview(file_path)\n",
    "\n",
    "clean_and_expand_new_car_feature(file_path)\n",
    "\n",
    "clean_new_car_specs(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning chennai cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\chennai_cars.xlsx\"\n",
    "\n",
    "new_car_details_cleaning(file_path,output_path=file_path)\n",
    "\n",
    "clean_and_expand_new_car_overview(file_path)\n",
    "\n",
    "clean_and_expand_new_car_feature(file_path)\n",
    "\n",
    "clean_new_car_specs(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Hydrabad cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\hyderabad_cars.xlsx\"\n",
    "\n",
    "new_car_details_cleaning(file_path,output_path=file_path)\n",
    "\n",
    "clean_and_expand_new_car_overview(file_path)\n",
    "\n",
    "clean_and_expand_new_car_feature(file_path)\n",
    "\n",
    "clean_new_car_specs(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Bangalore cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\bangalore_cars.xlsx\"\n",
    "\n",
    "new_car_details_cleaning(file_path,output_path=file_path)\n",
    "\n",
    "clean_and_expand_new_car_overview(file_path)\n",
    "\n",
    "clean_and_expand_new_car_feature(file_path)\n",
    "\n",
    "clean_new_car_specs(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def concat_features(file_path):\n",
    "   \n",
    "\n",
    "# Path to your Excel file\n",
    " excel_file = file_path\n",
    "\n",
    "# Read all sheets into a dictionary of DataFrames\n",
    " all_sheets = pd.read_excel(excel_file, sheet_name=None)\n",
    "\n",
    "# Combine all sheets horizontally (side by side)\n",
    " combined_df = pd.concat(all_sheets.values(), axis=1)\n",
    "\n",
    "# Save the combined DataFrame to a new Excel file (optional)\n",
    " combined_df.to_excel(file_path, index=False)\n",
    "\n",
    "# Display the combined DataFrame\n",
    " print(combined_df)\n",
    "    \n",
    "    # Display the combined DataFrame\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_ll(file_paths:list):\n",
    "    for i in file_paths:\n",
    "    concat_features(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\delhi.xlsx\",r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\kolkata_cars.xlsx\",r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\jaipur_cars.xlsx\",r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\chennai_cars.xlsx\",r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\hyderabad_cars.xlsx\",r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\bangalore_cars.xlsx\"]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_features(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\delhi.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_features(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\chennai_cars.xlsx\")\n",
    "concat_features(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\bangalore_cars.xlsx\")\n",
    "concat_features(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\hyderabad_cars.xlsx\")\n",
    "concat_features(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\kolkata_cars.xlsx\")\n",
    "concat_features(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\jaipur_cars.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_excel(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\delhi.xlsx\")\n",
    "df2 = pd.read_excel(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\bangalore_cars.xlsx\")\n",
    "df3 = pd.read_excel(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\chennai_cars.xlsx\")\n",
    "df4 = pd.read_excel(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\hyderabad_cars.xlsx\")\n",
    "df5 = pd.read_excel(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\kolkata_cars.xlsx\")\n",
    "df6 = pd.read_excel(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\data\\jaipur_cars.xlsx\")\n",
    "\n",
    "\n",
    "final_data=pd.concat([df1,df2,df3,df4,df5,df6],axis=0)\n",
    "final_data.to_excel(r\"C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\features_with_additional_data.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=final_data.drop(['priceActual', 'priceSaving', 'priceFixedText', 'heading', 'Unnamed: 1',\n",
    "                  'trendingText.desc','bottomData','data','Registration Year Icon',\n",
    "                 'Insurance Validity Icon','Fuel Type Icon','Seats Icon',\n",
    "                  'Kms Driven Icon' ,'Ownership Icon','Engine Displacement Icon',\n",
    "                  'Transmission Icon','Year of Manufacture Icon','RTO Icon','heading.1','commonIcon','Engine','Seats.1','owner','trendingText.imgUrl',\n",
    "                   'trendingText.heading' ]\n",
    "                  ,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>it</th>\n",
       "      <th>ft</th>\n",
       "      <th>bt</th>\n",
       "      <th>km</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ownerNo</th>\n",
       "      <th>oem</th>\n",
       "      <th>model</th>\n",
       "      <th>modelYear</th>\n",
       "      <th>centralVariantId</th>\n",
       "      <th>...</th>\n",
       "      <th>top_4</th>\n",
       "      <th>top_5</th>\n",
       "      <th>top_6</th>\n",
       "      <th>top_7</th>\n",
       "      <th>top_8</th>\n",
       "      <th>top_9</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Max Power</th>\n",
       "      <th>Torque</th>\n",
       "      <th>Wheel Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>107</td>\n",
       "      <td>2022</td>\n",
       "      <td>7121</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>18.00</td>\n",
       "      <td>113.43</td>\n",
       "      <td>250.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3472</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>206</td>\n",
       "      <td>2020</td>\n",
       "      <td>6837</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12.74</td>\n",
       "      <td>197.00</td>\n",
       "      <td>320.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>157</td>\n",
       "      <td>2019</td>\n",
       "      <td>6776</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21.01</td>\n",
       "      <td>81.80</td>\n",
       "      <td>113.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2177</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>2014</td>\n",
       "      <td>1193</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>16.50</td>\n",
       "      <td>86.80</td>\n",
       "      <td>109.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4026</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>224</td>\n",
       "      <td>2019</td>\n",
       "      <td>6760</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20.45</td>\n",
       "      <td>108.50</td>\n",
       "      <td>240.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>154</td>\n",
       "      <td>2002</td>\n",
       "      <td>3902</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>19.70</td>\n",
       "      <td>46.30</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2011</td>\n",
       "      <td>438</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>18.60</td>\n",
       "      <td>79.40</td>\n",
       "      <td>108.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3112</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>154</td>\n",
       "      <td>2007</td>\n",
       "      <td>3917</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>19.70</td>\n",
       "      <td>46.30</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>766</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>239</td>\n",
       "      <td>2022</td>\n",
       "      <td>8350</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>19.17</td>\n",
       "      <td>71.01</td>\n",
       "      <td>96.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1684</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>154</td>\n",
       "      <td>2009</td>\n",
       "      <td>3904</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>19.70</td>\n",
       "      <td>46.30</td>\n",
       "      <td>62.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5096 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      it  ft  bt    km  transmission  ownerNo  oem  model  modelYear  \\\n",
       "0      0   1   7   377             0        1   13    107       2022   \n",
       "2      0   4   7  3472             0        1   21    206       2020   \n",
       "9      0   4   2  2984             1        1   20    157       2019   \n",
       "10     0   4   2  2177             0        1    8     61       2014   \n",
       "11     0   1   7  4026             1        1   24    224       2019   \n",
       "...   ..  ..  ..   ...           ...      ...  ...    ...        ...   \n",
       "1113   0   4   2   326             1        1   20    154       2002   \n",
       "1115   0   4   2   237             1        1    2     27       2011   \n",
       "1116   0   4   2  3112             1        1   20    154       2007   \n",
       "1117   0   4   7   766             1        1   27    239       2022   \n",
       "1118   0   4   2  1684             1        1   20    154       2009   \n",
       "\n",
       "      centralVariantId  ...  top_4  top_5  top_6  top_7  top_8  top_9  \\\n",
       "0                 7121  ...     10      0      7      1      2      8   \n",
       "2                 6837  ...     10      0      7      1      2      8   \n",
       "9                 6776  ...     10      0      7      1      3      8   \n",
       "10                1193  ...     10      0      7      1      3      8   \n",
       "11                6760  ...     10      0      7      1      2      4   \n",
       "...                ...  ...    ...    ...    ...    ...    ...    ...   \n",
       "1113              3902  ...     10      6     21      3      9     12   \n",
       "1115               438  ...     10      4     12      4      5      4   \n",
       "1116              3917  ...     13      2      9     14     16     13   \n",
       "1117              8350  ...     10      0     15      1      3      8   \n",
       "1118              3904  ...     13      2      9     13      1     13   \n",
       "\n",
       "      Mileage  Max Power  Torque  Wheel Size  \n",
       "0       18.00     113.43   250.0        17.0  \n",
       "2       12.74     197.00   320.0        19.0  \n",
       "9       21.01      81.80   113.0        16.0  \n",
       "10      16.50      86.80   109.0        14.0  \n",
       "11      20.45     108.50   240.0        17.0  \n",
       "...       ...        ...     ...         ...  \n",
       "1113    19.70      46.30    62.0        12.0  \n",
       "1115    18.60      79.40   108.0        14.0  \n",
       "1116    19.70      46.30    62.0        12.0  \n",
       "1117    19.17      71.01    96.0        16.0  \n",
       "1118    19.70      46.30    62.0        12.0  \n",
       "\n",
       "[5096 rows x 35 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    it  ft  bt    km  transmission  ownerNo  oem  model  modelYear  \\\n",
      "0    0   1   7   377             0        1   13    107       2022   \n",
      "2    0   4   7  3472             0        1   21    206       2020   \n",
      "9    0   4   2  2984             1        1   20    157       2019   \n",
      "10   0   4   2  2177             0        1    8     61       2014   \n",
      "11   0   1   7  4026             1        1   24    224       2019   \n",
      "\n",
      "    centralVariantId  ...  top_4  top_5  top_6  top_7  top_8  top_9  Mileage  \\\n",
      "0               7121  ...     10      0      7      1      2      8    18.00   \n",
      "2               6837  ...     10      0      7      1      2      8    12.74   \n",
      "9               6776  ...     10      0      7      1      3      8    21.01   \n",
      "10              1193  ...     10      0      7      1      3      8    16.50   \n",
      "11              6760  ...     10      0      7      1      2      4    20.45   \n",
      "\n",
      "    Max Power  Torque  Wheel Size  \n",
      "0      113.43   250.0        17.0  \n",
      "2      197.00   320.0        19.0  \n",
      "9       81.80   113.0        16.0  \n",
      "10      86.80   109.0        14.0  \n",
      "11     108.50   240.0        17.0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Remove all non-numeric characters while keeping numbers and decimals\n",
    "# Assuming df is your DataFrame\n",
    "columns_to_clean = ['price', 'Registration Year', 'Seats', 'Kms Driven', \n",
    "                    'Engine Displacement', 'Mileage', 'Max Power', 'Torque','Wheel Size']\n",
    "\n",
    "# Remove non-numeric characters while keeping numbers and decimals\n",
    "df[columns_to_clean] = df[columns_to_clean].replace(r'[^0-9.]', '', regex=True)\n",
    "\n",
    "# Convert to numeric type\n",
    "df[columns_to_clean] = df[columns_to_clean].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating column by dtype for imputational process\n",
    "\n",
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "non_numeric_df = df.select_dtypes(exclude=['number'])\n",
    "\n",
    "nu_col = numeric_df.columns\n",
    "non_col = non_numeric_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "df= df.apply(lambda x : le.fit_transform(x) if x.dtypes == 'object' else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      it  ft  bt    km  transmission  ownerNo  oem  model  modelYear  \\\n",
      "0      0   1   7   377             0        1   13    107       2022   \n",
      "2      0   4   7  3472             0        1   21    206       2020   \n",
      "9      0   4   2  2984             1        1   20    157       2019   \n",
      "10     0   4   2  2177             0        1    8     61       2014   \n",
      "11     0   1   7  4026             1        1   24    224       2019   \n",
      "...   ..  ..  ..   ...           ...      ...  ...    ...        ...   \n",
      "1113   0   4   2   326             1        1   20    154       2002   \n",
      "1115   0   4   2   237             1        1    2     27       2011   \n",
      "1116   0   4   2  3112             1        1   20    154       2007   \n",
      "1117   0   4   7   766             1        1   27    239       2022   \n",
      "1118   0   4   2  1684             1        1   20    154       2009   \n",
      "\n",
      "      centralVariantId  ...  top_4  top_5  top_6  top_7  top_8  top_9  \\\n",
      "0                 7121  ...     10      0      7      1      2      8   \n",
      "2                 6837  ...     10      0      7      1      2      8   \n",
      "9                 6776  ...     10      0      7      1      3      8   \n",
      "10                1193  ...     10      0      7      1      3      8   \n",
      "11                6760  ...     10      0      7      1      2      4   \n",
      "...                ...  ...    ...    ...    ...    ...    ...    ...   \n",
      "1113              3902  ...     10      6     21      3      9     12   \n",
      "1115               438  ...     10      4     12      4      5      4   \n",
      "1116              3917  ...     13      2      9     14     16     13   \n",
      "1117              8350  ...     10      0     15      1      3      8   \n",
      "1118              3904  ...     13      2      9     13      1     13   \n",
      "\n",
      "      Mileage  Max Power  Torque  Wheel Size  \n",
      "0       18.00     113.43   250.0        17.0  \n",
      "2       12.74     197.00   320.0        19.0  \n",
      "9       21.01      81.80   113.0        16.0  \n",
      "10      16.50      86.80   109.0        14.0  \n",
      "11      20.45     108.50   240.0        17.0  \n",
      "...       ...        ...     ...         ...  \n",
      "1113    19.70      46.30    62.0        12.0  \n",
      "1115    18.60      79.40   108.0        14.0  \n",
      "1116    19.70      46.30    62.0        12.0  \n",
      "1117    19.17      71.01    96.0        16.0  \n",
      "1118    19.70      46.30    62.0        12.0  \n",
      "\n",
      "[5096 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(numeric_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # Enable IterativeImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "imputer = IterativeImputer(estimator=BayesianRidge(), max_iter=10, random_state=42)\n",
    "\n",
    "# Fit and transform the data\n",
    "imputed_data = imputer.fit_transform(df)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df = pd.DataFrame(imputed_data, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run if the current trying algorithm is not supported the iterative imputation\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "numeric_df= imputer.fit_transform(numeric_df)\n",
    "\n",
    "numeric_df = pd.DataFrame(numeric_df, columns =nu_col  )\n",
    "\n",
    "imputer1 = SimpleImputer(strategy = \"constant\")\n",
    "non_numeric_df = imputer1.fit_transform(non_numeric_df)\n",
    "\n",
    "non_numeric_df = pd.DataFrame(non_numeric_df, columns = non_col )\n",
    "\n",
    "df = pd.concat([numeric_df, non_numeric_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(r'C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\car_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\car_features.xlsx')\n",
    "\n",
    "# Replace 0 values in the 'price' column with the mean of the non-zero values\n",
    "mean_price = df[df['price'] != 0]['price'].mean()\n",
    "df['price'] = df['price'].replace(0, mean_price)\n",
    "\n",
    "df.to_excel(r'C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\car_features.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "#df = pd.read_excel(r'C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\car_features.xlsx')\n",
    "\n",
    "# Calculate the mean of non-zero values in the 'price' column\n",
    "mean_price = df[df['price'] != 0]['price'].mean()\n",
    "\n",
    "# Replace 0 values in the 'price' column with the mean of the non-zero values\n",
    "df['price'] = df['price'].replace(0, mean_price)\n",
    "\n",
    "\n",
    "df['price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(r'C:\\Users\\loges\\Desktop\\python\\sample projects\\GUVI\\MLapp\\car_features_without_impute.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['ft','bt','km','oem','transmission','ownerNo','modelYear','Engine Displacement',\"Seats\",\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r'car_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['ft','bt','km','oem','transmission','ownerNo','modelYear','Engine Displacement',\"Seats\",\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(self):\n",
    "\n",
    "\n",
    "            models = {\n",
    "                'Linear Regression': LinearRegression(),\n",
    "                'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "                'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42),\n",
    "                'XGBoost Regressor': XGBRegressor(random_state=42, verbosity=0)\n",
    "            }\n",
    "\n",
    "            # 3. Define parameter grids\n",
    "            param_grids = {\n",
    "                'Linear Regression': {\n",
    "                    'fit_intercept': [True, False],\n",
    "                    'positive': [True, False]\n",
    "                },\n",
    "                'Random Forest Regressor': {\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'max_depth': [None, 10],\n",
    "                    'min_samples_split': [2, 5],\n",
    "                    'min_samples_leaf': [1, 2],\n",
    "                    'max_features': ['auto', 'sqrt']\n",
    "                },\n",
    "                'Gradient Boosting Regressor': {\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'learning_rate': [0.05, 0.1],\n",
    "                    'max_depth': [3, 5],\n",
    "                    'min_samples_split': [2, 5],\n",
    "                    'min_samples_leaf': [1, 2],\n",
    "                    'subsample': [0.8, 1.0],\n",
    "                    'max_features': ['auto', 'sqrt']\n",
    "                },\n",
    "                'XGBoost Regressor': {\n",
    "                    'n_estimators': [100, 200],\n",
    "                    'learning_rate': [0.05, 0.1],\n",
    "                    'max_depth': [3, 5],\n",
    "                    'subsample': [0.8, 1.0],\n",
    "                    'colsample_bytree': [0.8, 1.0],\n",
    "                    'gamma': [0, 1],\n",
    "                    'reg_alpha': [0, 0.1],\n",
    "                    'reg_lambda': [1, 2]\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # 4. Run GridSearchCV for each model\n",
    "            results = []\n",
    "\n",
    "            for name, model in models.items():\n",
    "                print(f\"\\nüîç Running GridSearchCV for {name}...\")\n",
    "                grid = GridSearchCV(\n",
    "                    estimator=model,\n",
    "                    param_grid=param_grids[name],\n",
    "                    cv=3,  # 3-fold cross-validation\n",
    "                    scoring='neg_mean_squared_error',\n",
    "                    n_jobs=-1,\n",
    "                    verbose=0\n",
    "                )\n",
    "                grid.fit(self.x_train, self.y_train)\n",
    "\n",
    "                best_model = grid.best_estimator_\n",
    "                y_pred = best_model.predict(self.x_train)\n",
    "\n",
    "                mse = mean_squared_error(y_test, y_pred)\n",
    "                r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "                results.append({\n",
    "                    \"Model\": name,\n",
    "                    \"Best Params\": grid.best_params_,\n",
    "                    \"CV Score (neg MSE)\": grid.best_score_,\n",
    "                    \"Test MSE\": mse,\n",
    "                    \"Test R2\": r2\n",
    "                })\n",
    "\n",
    "            # 5. Display results as DataFrame\n",
    "            results_df = pd.DataFrame(results)\n",
    "            print(\"\\n‚úÖ GridSearch Results:\")\n",
    "            print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
